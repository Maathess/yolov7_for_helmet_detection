{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0b9edc",
   "metadata": {},
   "source": [
    "Lien du projet GitHub \"__Yolov7__\" : https://github.com/WongKinYiu/yolov7 </br>\n",
    "Lien du dataset : https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection\n",
    "\n",
    "*Pour toute reproduction, veuillez avoir l'accord de l'√©quipe du cours \"__D√©tection d'objets: l'intelligence artificielle au service de la s√©curit√©__\"*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea089657",
   "metadata": {},
   "source": [
    "# <center>TP : Projet \"Safety First\" üë∑ - BricoLor x DetectAId</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b7a7b5",
   "metadata": {},
   "source": [
    "***\n",
    "### Enonc√© : \n",
    "Notre entreprise \"__DetecAId__\" (se pronon√ßant \"detected\" ou \"detect aid\"), propose des services de mise en place de solutions bas√©es sur la technologie de la <ins>d√©tection d'objets</ins> dans le cadre de la s√©curit√©. \n",
    "Une entreprise du nom de __BricoLor__ (entreprise de construction), nous sollicite car ils ont √©t√© mobilis√©s pour la construction d'un stade dans le cadre du projet __JO2024__. \n",
    "\n",
    "Ils souhaiteraient mener √† bien ce projet mobilisant plus de <ins>1000 employ√©s</ins> (sur  le terrain), et ils ont d√©cid√© pour cela de mettre un point de priorit√© sur la s√©curit√©, notamment sur le port des <ins>EPI</ins> (Equipement de protection Individuelle) pour les personnes se trouvant sur le chantier du futur stade.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13769963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.0\n"
     ]
    }
   ],
   "source": [
    "#Verify your python version >=3.6 != 3.10 (3.9 recommended)\n",
    "!py --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c4375",
   "metadata": {},
   "source": [
    "***\n",
    "#### TODO 1 - Utilisation du mod√®le YOLOv7\n",
    "__Tester la detection d'objet YOLOv7 sur une image et/ou vid√©o__ - 2 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39087642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47659d29",
   "metadata": {},
   "source": [
    "Voici √† quoi doit ressembler l'architecture du projet suite √† l'ajout du dataset\n",
    "\n",
    "```bash\n",
    "yolov7 \n",
    "‚îî‚îÄ‚îÄ‚îÄ dataset\n",
    "   ‚îÇ\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ images\n",
    "            ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ test\n",
    "            ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ train\n",
    "            ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ val\n",
    "    ‚îî‚îÄ‚îÄ  labels\n",
    "            ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ test\n",
    "            ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ train \n",
    "            ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ val \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e4244",
   "metadata": {},
   "source": [
    "***\n",
    "#### TODO 2 - Extraire les informations des annotations (fichier .xml)\n",
    "__Remplir les lignes de codes manquantes__ - 8 points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "# Dictionary that maps class names to IDs\n",
    "class_name_to_id_mapping = {\"helmet\": 0,\n",
    "                           \"person\": 1,\n",
    "                           \"head\": 2}\n",
    "\n",
    "def extract_info_from_xml(xml_file):\n",
    "    root = ET.parse(xml_file).getroot()\n",
    "    \n",
    "    # Initialise the info dict \n",
    "    info_dict = {}\n",
    "    info_dict['bboxes'] = []\n",
    "    \n",
    "    #### TODO 2.1 - Parse the XML Tree ####\n",
    "    #Write your code here\n",
    "    \n",
    "    \n",
    "        #### TODO 2.2 - Get the file name ####\n",
    "        #Write your code here \n",
    "          \n",
    "        \n",
    "        #### TODO 2.3 - Get the image size ####\n",
    "        #Write your code here \n",
    "\n",
    "        \n",
    "        #### TODO 2.4 - Get details of the bounding box ####\n",
    "        #Write your code here\n",
    "    \n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee57380",
   "metadata": {},
   "source": [
    "***\n",
    "#### Conversion des donn√©es sous le format YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the info dict to the required yolo format and write it to disk\n",
    "def convert_to_yolov7(info_dict):\n",
    "    print_buffer = []\n",
    "    \n",
    "    # For each bounding box\n",
    "    for b in info_dict[\"bboxes\"]:\n",
    "        try:\n",
    "            class_id = class_name_to_id_mapping[b[\"class\"]]\n",
    "        except KeyError:\n",
    "            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
    "        \n",
    "        # Transform the bbox co-ordinates as per the format required by YOLO v7\n",
    "        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n",
    "        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n",
    "        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n",
    "        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n",
    "        \n",
    "        # Normalise the co-ordinates by the dimensions of the image\n",
    "        image_w, image_h, image_c = info_dict[\"image_size\"]  \n",
    "        b_center_x /= image_w \n",
    "        b_center_y /= image_h \n",
    "        b_width    /= image_w \n",
    "        b_height   /= image_h \n",
    "        \n",
    "        #Write the bbox details to the file \n",
    "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
    "        \n",
    "    # Name of the file which we have to save \n",
    "    save_file_name = os.path.join(\"annotations\", info_dict[\"filename\"].replace(\"png\", \"txt\"))\n",
    "    \n",
    "    # Save the annotation to disk\n",
    "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))\n",
    "\n",
    "annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"xml\"]\n",
    "annotations.sort()\n",
    "\n",
    "# Convert and save the annotations\n",
    "for ann in tqdm(annotations):\n",
    "    info_dict = extract_info_from_xml(ann)\n",
    "    convert_to_yolov7(info_dict)\n",
    "annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3ac115",
   "metadata": {},
   "source": [
    "***\n",
    "#### TODO 3 - Spliting du dataset\n",
    "__Remplir les lignes manquantes__ - 4 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "#### TODO 3.1 - Read images and annotations ####\n",
    "#Write your code here\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "#### TODO 3.2 - Split the dataset into train-valid-test splits ####\n",
    "#Write your code here\n",
    "\n",
    "#Utility function to move images \n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            shutil.move(f, destination_folder)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False\n",
    "\n",
    "#### TODO 3.2 - Move the splits into their folders ####\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182e67d",
   "metadata": {},
   "source": [
    "***\n",
    "#### TODO 4 - Entra√Ænement du mod√®le via transfert-learning\n",
    "Ex√©cuter la commande permettant d'entra√Æner le mod√®le sur le dataset - 2 points (+ points bonus)\n",
    "\n",
    "Le choix des hyperparam√®tres depend de vous, des points bonus seront attribu√©s selon le fine-tuning du mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dedc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34aa351",
   "metadata": {},
   "source": [
    "***\n",
    "#### TODO 5 - Inf√©rence sur le mod√®le entra√Æn√© \n",
    "Afficher les r√©sultat de l'entra√Ænement - 2 points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c2de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e16f0e",
   "metadata": {},
   "source": [
    "***\n",
    "#### TODO 6 - Inf√©rence sur le mod√®le entra√Æn√© \n",
    "Ex√©cuter la commande permettant de r√©aliser une d√©tection sur une image et/ou vid√©o √† l'aide du mod√®le entra√Æn√© ci-dessus et afficher les r√©sultats dans le notebook et les interpr√©ter - 2 points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvtest",
   "language": "python",
   "name": "venvtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
